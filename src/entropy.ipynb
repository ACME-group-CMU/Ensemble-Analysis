{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698336b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "VASP QUESTS Entropy Analysis Functions\n",
    "======================================\n",
    "\n",
    "Functions to compute information entropy on VASP structures using QUESTS.\n",
    "Designed to integrate with existing ensemble analysis pipeline.\n",
    "\n",
    "Usage:\n",
    "    from quests_analysis import compute_entropy_analysis, entropy_sampling\n",
    "\n",
    "Author: Assistant\n",
    "Based on: Schwalbe-Koda et al. 2024 - Model-free quantification of completeness...\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Existing imports from your pipeline\n",
    "from src.data_management_v2 import load_structures, load_energies\n",
    "\n",
    "# QUESTS imports (actual API)\n",
    "try:\n",
    "    from quests import entropy, descriptor, matrix\n",
    "    from quests.tools import plotting\n",
    "except ImportError:\n",
    "    print(\"QUESTS not found. Install with: pip install git+https://github.com/dskoda/quests.git\")\n",
    "    raise\n",
    "\n",
    "\n",
    "def compute_entropy_analysis(struct_ids, k_neighbors=32, cutoff=5.0, bandwidth=0.015, \n",
    "                           save_descriptors=False):\n",
    "    \"\"\"\n",
    "    Compute QUESTS information entropy analysis for a set of structures.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    struct_ids : list of int\n",
    "        Structure IDs to analyze (should exist in your data pipeline)\n",
    "    k_neighbors : int\n",
    "        Number of nearest neighbors for descriptor (default: 32)\n",
    "    cutoff : float  \n",
    "        Cutoff radius in Angstroms (default: 5.0)\n",
    "    bandwidth : float\n",
    "        Bandwidth for KDE in A^-1 (default: 0.015) \n",
    "    save_descriptors : bool\n",
    "        Whether to save computed descriptors\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Results containing entropy values, descriptors, etc.\n",
    "    \"\"\"\n",
    "    print(f\"Computing QUESTS entropy analysis for {len(struct_ids)} structures\")\n",
    "    print(f\"Parameters: k={k_neighbors}, cutoff={cutoff}Å, bandwidth={bandwidth}Å⁻¹\")\n",
    "    \n",
    "    # Load structures using existing pipeline\n",
    "    print(\"Loading structures...\")\n",
    "    structures_dict = load_structures(struct_ids)\n",
    "    valid_ids = [sid for sid in struct_ids if sid in structures_dict]\n",
    "    \n",
    "    if not valid_ids:\n",
    "        raise ValueError(\"No valid structures found!\")\n",
    "    \n",
    "    print(f\"Loaded {len(valid_ids)} valid structures\")\n",
    "    \n",
    "    # Convert pymatgen structures to format QUESTS expects\n",
    "    print(\"Converting structures for QUESTS...\")\n",
    "    from pymatgen.io.ase import AseAtomsAdaptor\n",
    "    \n",
    "    atoms_list = []\n",
    "    adaptor = AseAtomsAdaptor()\n",
    "    \n",
    "    for sid in valid_ids:\n",
    "        structure = structures_dict[sid]\n",
    "        # Convert pymatgen Structure to ASE Atoms (QUESTS expects ASE format)\n",
    "        atoms = adaptor.get_atoms(structure)\n",
    "        atoms_list.append(atoms)\n",
    "    \n",
    "    # Compute descriptors using QUESTS\n",
    "    print(\"Computing atomic environment descriptors...\")\n",
    "    descriptors = descriptor.get_descriptors(\n",
    "        atoms_list, \n",
    "        k=k_neighbors, \n",
    "        cutoff=cutoff,\n",
    "        concat=True\n",
    "    )\n",
    "    print(f\"Computed descriptors shape: {descriptors.shape}\")\n",
    "    \n",
    "    # Compute total entropy\n",
    "    print(\"Computing information entropy...\")\n",
    "    H_total = entropy.entropy(descriptors, h=bandwidth)\n",
    "    \n",
    "    # Compute differential entropy for each structure\n",
    "    print(\"Computing differential entropies...\")\n",
    "    delta_H_values = []\n",
    "    \n",
    "    # Get number of environments per structure to split descriptors\n",
    "    env_counts = [len(atoms) for atoms in atoms_list]\n",
    "    start_idx = 0\n",
    "    \n",
    "    for i, (struct_id, count) in enumerate(tqdm(zip(valid_ids, env_counts), desc=\"Computing δH\")):\n",
    "        # Get descriptors for this structure's environments\n",
    "        end_idx = start_idx + count\n",
    "        struct_descriptors = descriptors[start_idx:end_idx]\n",
    "        \n",
    "        # Get reference descriptors (all others)\n",
    "        if len(descriptors) > count:\n",
    "            other_indices = list(range(len(descriptors)))\n",
    "            struct_indices = list(range(start_idx, end_idx))\n",
    "            ref_indices = [idx for idx in other_indices if idx not in struct_indices]\n",
    "            reference_descriptors = descriptors[ref_indices]\n",
    "            \n",
    "            # Compute differential entropy for this structure\n",
    "            delta_H = entropy.delta_entropy(\n",
    "                struct_descriptors, \n",
    "                reference_descriptors, \n",
    "                h=bandwidth\n",
    "            )\n",
    "            delta_H_values.append(np.mean(delta_H))  # Average over environments\n",
    "        else:\n",
    "            delta_H_values.append(0.0)\n",
    "        \n",
    "        start_idx = end_idx\n",
    "    \n",
    "    # Load energies for correlation analysis\n",
    "    energies_dict = load_energies(valid_ids)\n",
    "    energies = [energies_dict.get(sid, np.nan) for sid in valid_ids]\n",
    "    \n",
    "    # Compile results\n",
    "    results = {\n",
    "        'struct_ids': valid_ids,\n",
    "        'total_entropy': H_total,\n",
    "        'differential_entropies': np.array(delta_H_values),\n",
    "        'energies': np.array(energies),\n",
    "        'descriptors': descriptors if save_descriptors else None,\n",
    "        'parameters': {\n",
    "            'k_neighbors': k_neighbors,\n",
    "            'cutoff': cutoff,\n",
    "            'bandwidth': bandwidth,\n",
    "            'n_structures': len(valid_ids),\n",
    "            'descriptor_dim': descriptors.shape[1] if descriptors is not None else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create summary DataFrame\n",
    "    results['summary_df'] = pd.DataFrame({\n",
    "        'struct_id': valid_ids,\n",
    "        'delta_H': delta_H_values,\n",
    "        'energy': energies,\n",
    "        'novelty_rank': np.argsort(np.argsort(-np.array(delta_H_values))) + 1\n",
    "    })\n",
    "    \n",
    "    print(f\"Analysis complete!\")\n",
    "    print(f\"Total entropy: {H_total:.3f} nats\")\n",
    "    print(f\"Mean δH: {np.mean(delta_H_values):.3f} ± {np.std(delta_H_values):.3f} nats\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def entropy_sampling(struct_ids, sample_size=100, method='high_entropy', **entropy_kwargs):\n",
    "    \"\"\"\n",
    "    Sample structures based on entropy criteria using QUESTS.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    struct_ids : list of int\n",
    "        Structure IDs to sample from\n",
    "    sample_size : int\n",
    "        Number of structures to sample\n",
    "    method : str\n",
    "        Sampling method: 'high_entropy', 'low_entropy', 'diverse_entropy'\n",
    "    **entropy_kwargs : dict\n",
    "        Additional arguments for compute_entropy_analysis()\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray : Sampled structure IDs\n",
    "    \"\"\"\n",
    "    print(f\"Entropy-based sampling: {method}, n={sample_size}\")\n",
    "    \n",
    "    # Compute entropy analysis\n",
    "    results = compute_entropy_analysis(struct_ids, **entropy_kwargs)\n",
    "    delta_H = results['differential_entropies']\n",
    "    valid_ids = results['struct_ids']\n",
    "    \n",
    "    if sample_size > len(valid_ids):\n",
    "        print(f\"Warning: sample_size {sample_size} > available structures {len(valid_ids)}\")\n",
    "        sample_size = len(valid_ids)\n",
    "    \n",
    "    if method == 'high_entropy':\n",
    "        # Sample structures with highest differential entropy (most novel)\n",
    "        indices = np.argsort(delta_H)[-sample_size:]\n",
    "        \n",
    "    elif method == 'low_entropy':\n",
    "        # Sample structures with lowest differential entropy (most representative)\n",
    "        indices = np.argsort(delta_H)[:sample_size]\n",
    "        \n",
    "    elif method == 'diverse_entropy':\n",
    "        # Sample across entropy range for diversity\n",
    "        indices = np.linspace(0, len(delta_H)-1, sample_size, dtype=int)\n",
    "        indices = np.argsort(delta_H)[indices]\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown sampling method: {method}\")\n",
    "    \n",
    "    sampled_ids = np.array([valid_ids[i] for i in indices])\n",
    "    \n",
    "    print(f\"Sampled {len(sampled_ids)} structures\")\n",
    "    print(f\"δH range: {delta_H[indices].min():.3f} to {delta_H[indices].max():.3f} nats\")\n",
    "    \n",
    "    return np.sort(sampled_ids)\n",
    "\n",
    "\n",
    "def identify_outliers(struct_ids, threshold_sigma=2.0, **entropy_kwargs):\n",
    "    \"\"\"\n",
    "    Identify structural outliers using differential entropy.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    struct_ids : list of int\n",
    "        Structure IDs to analyze\n",
    "    threshold_sigma : float\n",
    "        Number of standard deviations above mean to consider outlier\n",
    "    **entropy_kwargs : dict\n",
    "        Additional arguments for compute_entropy_analysis()\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Outlier analysis results\n",
    "    \"\"\"\n",
    "    print(f\"Identifying outliers (threshold: {threshold_sigma}σ)\")\n",
    "    \n",
    "    # Compute entropy analysis\n",
    "    results = compute_entropy_analysis(struct_ids, **entropy_kwargs)\n",
    "    delta_H = results['differential_entropies']\n",
    "    valid_ids = results['struct_ids']\n",
    "    \n",
    "    # Define outlier threshold\n",
    "    mean_dH = np.mean(delta_H)\n",
    "    std_dH = np.std(delta_H)\n",
    "    threshold = mean_dH + threshold_sigma * std_dH\n",
    "    \n",
    "    # Identify outliers\n",
    "    outlier_mask = delta_H > threshold\n",
    "    outlier_ids = np.array(valid_ids)[outlier_mask]\n",
    "    outlier_entropies = delta_H[outlier_mask]\n",
    "    \n",
    "    print(f\"Found {len(outlier_ids)} outliers\")\n",
    "    print(f\"Threshold: {threshold:.3f} nats\")\n",
    "    \n",
    "    return {\n",
    "        'outlier_ids': outlier_ids,\n",
    "        'outlier_entropies': outlier_entropies,\n",
    "        'threshold': threshold,\n",
    "        'mean_entropy': mean_dH,\n",
    "        'std_entropy': std_dH,\n",
    "        'all_results': results\n",
    "    }\n",
    "\n",
    "\n",
    "def entropy_learning_curve(struct_ids, sample_sizes=None, n_trials=3, **entropy_kwargs):\n",
    "    \"\"\"\n",
    "    Compute learning curve showing how entropy scales with dataset size.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    struct_ids : list of int\n",
    "        Structure IDs to analyze\n",
    "    sample_sizes : list of int\n",
    "        Sample sizes to test (default: logarithmic spacing)\n",
    "    n_trials : int\n",
    "        Number of trials per sample size\n",
    "    **entropy_kwargs : dict\n",
    "        Additional arguments for compute_entropy_analysis()\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Learning curve results\n",
    "    \"\"\"\n",
    "    if sample_sizes is None:\n",
    "        max_size = min(len(struct_ids), 500)  # Cap at 500 for speed\n",
    "        sample_sizes = np.logspace(1, np.log10(max_size), 8, dtype=int)\n",
    "        sample_sizes = np.unique(np.clip(sample_sizes, 10, max_size))\n",
    "    \n",
    "    print(f\"Computing entropy learning curve for {len(sample_sizes)} sample sizes\")\n",
    "    \n",
    "    results = {\n",
    "        'sample_sizes': [],\n",
    "        'mean_entropies': [],\n",
    "        'std_entropies': [],\n",
    "        'all_entropies': []\n",
    "    }\n",
    "    \n",
    "    for size in tqdm(sample_sizes, desc=\"Sample sizes\"):\n",
    "        size_entropies = []\n",
    "        \n",
    "        for trial in range(n_trials):\n",
    "            # Random sample\n",
    "            sample_ids = np.random.choice(struct_ids, size=size, replace=False)\n",
    "            \n",
    "            # Compute entropy\n",
    "            trial_results = compute_entropy_analysis(sample_ids.tolist(), **entropy_kwargs)\n",
    "            size_entropies.append(trial_results['total_entropy'])\n",
    "        \n",
    "        results['sample_sizes'].append(size)\n",
    "        results['mean_entropies'].append(np.mean(size_entropies))\n",
    "        results['std_entropies'].append(np.std(size_entropies))\n",
    "        results['all_entropies'].append(size_entropies)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_entropy_analysis(results, figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Plot entropy analysis results.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results : dict\n",
    "        Results from compute_entropy_analysis()\n",
    "    figsize : tuple\n",
    "        Figure size\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure : The created figure\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=figsize)\n",
    "    \n",
    "    # Plot 1: Differential entropy distribution\n",
    "    axes[0,0].hist(results['differential_entropies'], bins=30, alpha=0.7, edgecolor='black')\n",
    "    axes[0,0].set_xlabel('Differential Entropy δH (nats)')\n",
    "    axes[0,0].set_ylabel('Count')\n",
    "    axes[0,0].set_title('Distribution of Differential Entropies')\n",
    "    axes[0,0].axvline(np.mean(results['differential_entropies']), color='red', \n",
    "                     linestyle='--', label='Mean')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # Plot 2: Energy vs entropy correlation\n",
    "    valid_energies = ~np.isnan(results['energies'])\n",
    "    if np.any(valid_energies):\n",
    "        axes[0,1].scatter(results['energies'][valid_energies], \n",
    "                         results['differential_entropies'][valid_energies], alpha=0.6)\n",
    "        axes[0,1].set_xlabel('Energy')\n",
    "        axes[0,1].set_ylabel('Differential Entropy δH (nats)')\n",
    "        axes[0,1].set_title('Energy vs Differential Entropy')\n",
    "        \n",
    "        # Correlation coefficient\n",
    "        corr = np.corrcoef(results['energies'][valid_energies], \n",
    "                          results['differential_entropies'][valid_energies])[0,1]\n",
    "        axes[0,1].text(0.05, 0.95, f'r = {corr:.3f}', transform=axes[0,1].transAxes,\n",
    "                      bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Plot 3: Structure novelty ranking\n",
    "    novelty_ranks = np.argsort(np.argsort(-results['differential_entropies'])) + 1\n",
    "    axes[1,0].scatter(novelty_ranks, results['differential_entropies'], alpha=0.6)\n",
    "    axes[1,0].set_xlabel('Novelty Rank')\n",
    "    axes[1,0].set_ylabel('Differential Entropy δH (nats)')\n",
    "    axes[1,0].set_title('Structure Novelty Ranking')\n",
    "    \n",
    "    # Plot 4: Summary statistics\n",
    "    axes[1,1].axis('off')\n",
    "    stats_text = f\"\"\"\n",
    "    Analysis Summary\n",
    "    ================\n",
    "    Total Structures: {len(results['struct_ids'])}\n",
    "    Total Entropy: {results['total_entropy']:.3f} nats\n",
    "    \n",
    "    Differential Entropy:\n",
    "      Mean: {np.mean(results['differential_entropies']):.3f} nats\n",
    "      Std:  {np.std(results['differential_entropies']):.3f} nats\n",
    "      Min:  {np.min(results['differential_entropies']):.3f} nats\n",
    "      Max:  {np.max(results['differential_entropies']):.3f} nats\n",
    "    \n",
    "    Parameters:\n",
    "      k_neighbors: {results['parameters']['k_neighbors']}\n",
    "      cutoff: {results['parameters']['cutoff']} Å\n",
    "      bandwidth: {results['parameters']['bandwidth']} Å⁻¹\n",
    "    \"\"\"\n",
    "    axes[1,1].text(0.05, 0.95, stats_text, transform=axes[1,1].transAxes,\n",
    "                  fontfamily='monospace', fontsize=10, verticalalignment='top')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "\n",
    "def compare_entropy_sampling_methods(struct_ids, sample_size=100, **entropy_kwargs):\n",
    "    \"\"\"\n",
    "    Compare different entropy-based sampling methods.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    struct_ids : list of int\n",
    "        Structure IDs to sample from\n",
    "    sample_size : int\n",
    "        Number of structures to sample with each method\n",
    "    **entropy_kwargs : dict\n",
    "        Additional arguments for entropy analysis\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Comparison results\n",
    "    \"\"\"\n",
    "    print(f\"Comparing entropy sampling methods (n={sample_size})\")\n",
    "    \n",
    "    methods = ['high_entropy', 'low_entropy', 'diverse_entropy']\n",
    "    results = {}\n",
    "    \n",
    "    for method in methods:\n",
    "        print(f\"\\nSampling with method: {method}\")\n",
    "        sampled_ids = entropy_sampling(struct_ids, sample_size, method, **entropy_kwargs)\n",
    "        results[method] = sampled_ids\n",
    "    \n",
    "    return results\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
